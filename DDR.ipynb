{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjTCK5AJQXGF",
    "outputId": "9eef2db6-e161-4bcb-a4f2-c1af0e451728"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQSSTii9QesL"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyxckmvhSdU4"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MOVES = [\n",
    "    \"center\",\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"downleft\",\n",
    "    \"downright\",\n",
    "    \"upleft\",\n",
    "    \"upright\",\n",
    "    \"updown\",\n",
    "    \"leftright\",\n",
    "]\n",
    "SAMPLE_RATE = 16000  # Standard sample rate for audio\n",
    "WINDOW_SIZES = [1, 5, \"full\"]  # in seconds - 3 required window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-Umv4YhTj-9"
   },
   "outputs": [],
   "source": [
    "# Sample function to resample the input audio to 16kHz\n",
    "def load_audio_16k(path):\n",
    "    audio, sr = librosa.load(path, SAMPLE_RATE=16000)  # Resample to 16 kHz\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ADjNeR3VX_n"
   },
   "source": [
    "##Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tE__CqgZYqz"
   },
   "source": [
    "notes: wave 1 and wave 2 cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import (\n",
    "    extract_all_features_with_xcorr,\n",
    ")\n",
    "from stomp_detector import StompDetector\n",
    "from file_stream import FileStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiP4kvhmUezD"
   },
   "source": [
    "##Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGlWvp7oUdip"
   },
   "outputs": [],
   "source": [
    "def list_audio_files(base_path):\n",
    "    \"\"\"List all valid audio files in dataset directory.\"\"\"\n",
    "    audio_files = []\n",
    "    if os.path.exists(base_path):\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                    # Extract move from filename (last part before .wav)\n",
    "                    basename = os.path.splitext(file)[0]\n",
    "                    # Get the last underscore-separated part as the move\n",
    "                    parts = basename.split(\"_\")\n",
    "                    move = parts[-1]\n",
    "                    if move in MOVES:\n",
    "                        audio_files.append(os.path.join(root, file))\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "def load_and_extract_features_xcorr(audio_files):\n",
    "    \"\"\"\n",
    "    Load audio files, split them into individual stomps, and extract features\n",
    "    for EACH stomp instead of one feature vector per whole file.\n",
    "    \"\"\"\n",
    "    X, y, metadata = [], [], []\n",
    "\n",
    "    # Parameters for streaming\n",
    "    window_ms = 200\n",
    "    step_ms = 100\n",
    "    sr = SAMPLE_RATE\n",
    "\n",
    "    window_frames = int((window_ms / 1000.0) * sr)\n",
    "    step_frames = int((step_ms / 1000.0) * sr)\n",
    "    channels = 2  # Assuming stereo\n",
    "\n",
    "    for file in audio_files:\n",
    "        try:\n",
    "            # Use the stomp detector with streaming\n",
    "            detector = StompDetector(sr=sr, energy_threshold=0.3)\n",
    "            audio_buffer = np.zeros((window_frames, channels), dtype=np.float32)\n",
    "\n",
    "            stomps = []\n",
    "\n",
    "            # Stream the file\n",
    "            stream_ctx = FileStream(file, step_frames)\n",
    "\n",
    "            # If the file stream has a different SR, we might need to handle it,\n",
    "            # but FileStream loads with librosa.load(sr=None), so it keeps original SR.\n",
    "            # StompDetector expects input to match its sr or it resamples internally?\n",
    "            # StompDetector.detect resamples to 16000 if needed.\n",
    "            # But StompDetector init takes sr.\n",
    "\n",
    "            # Let's check FileStream sr\n",
    "            if stream_ctx.sr != sr:\n",
    "                # Re-init detector with file's SR if different\n",
    "                detector = StompDetector(sr=stream_ctx.sr, energy_threshold=0.2)\n",
    "                # Recalculate buffer size for the file's SR\n",
    "                file_window_frames = int((window_ms / 1000.0) * stream_ctx.sr)\n",
    "                audio_buffer = np.zeros(\n",
    "                    (file_window_frames, channels), dtype=np.float32\n",
    "                )\n",
    "\n",
    "            with stream_ctx as stream:\n",
    "                while True:\n",
    "                    if stream.finished:\n",
    "                        break\n",
    "\n",
    "                    chunk, overflow = stream.read(step_frames)\n",
    "\n",
    "                    # Update rolling buffer\n",
    "                    audio_buffer = np.roll(audio_buffer, -len(chunk), axis=0)\n",
    "                    audio_buffer[-len(chunk) :] = chunk\n",
    "\n",
    "                    # Detect on the full window\n",
    "                    detected_stomps = detector.detect(audio_buffer)\n",
    "                    stomps.extend(detected_stomps)\n",
    "\n",
    "            print(f\"{file}: {len(stomps)} stomps detected\")\n",
    "\n",
    "            if len(stomps) == 0:\n",
    "                print(f\"Skipping {file}: no stomps found\")\n",
    "                continue\n",
    "\n",
    "            basename = os.path.basename(file)\n",
    "            basename_no_ext = os.path.splitext(basename)[0]\n",
    "            move = basename_no_ext.split(\"_\")[-1]\n",
    "\n",
    "            move_idx = MOVES.index(move)\n",
    "\n",
    "            for i, stomp in enumerate(stomps):\n",
    "                # Skip tiny fragments just in case\n",
    "                if len(stomp) < SAMPLE_RATE * 0.05:\n",
    "                    continue\n",
    "                # print(f\"stomp shape: {stomp.shape}\")\n",
    "                features = extract_all_features_with_xcorr(stomp, SAMPLE_RATE)\n",
    "\n",
    "                X.append(features)\n",
    "                y.append(move_idx)\n",
    "                metadata.append(\n",
    "                    {\n",
    "                        \"file\": basename,\n",
    "                        \"move\": move,\n",
    "                        \"stomp_idx\": i,\n",
    "                        \"n_samples\": len(stomp),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {file} due to error: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return np.array(X), np.array(y), pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, metadata, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepares data for training and testing: scales features and performs train-test split.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hL9PGxzAHVeR",
    "outputId": "526f4208-7f4c-4f56-95f9-ccd255c9f6f8"
   },
   "outputs": [],
   "source": [
    "audio_files = list_audio_files(dataset_path)\n",
    "X, y, metadata = load_and_extract_features_xcorr(audio_files)\n",
    "data = prepare_data(X, y, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zgHsvZSd_28F",
    "outputId": "1b4b6aff-01a7-4754-d97f-b1ad74f27284"
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "mlp_clr = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128),  # two hidden layers\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,  # L2 regularization\n",
    "    batch_size=32,\n",
    "    learning_rate=\"adaptive\",\n",
    "    max_iter=300,\n",
    "    early_stopping=True,  # use a validation split internally\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42,\n",
    "    verbose=True,  # prints training progress\n",
    ")\n",
    "\n",
    "mlp = make_pipeline(StandardScaler(), mlp_clr)\n",
    "\n",
    "# Train the neural network\n",
    "print(\"Training MLP neural network...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nn = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(\"\\n=== Neural Network (MLP) Performance ===\")\n",
    "print(f\"Test Accuracy: {nn_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n=== Classification Report (Neural Network) ===\")\n",
    "print(classification_report(y_test, y_pred_nn, target_names=MOVES))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "print(\"\\n=== Confusion Matrix (Neural Network) ===\")\n",
    "print(cm_nn)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm_nn, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=MOVES, yticklabels=MOVES\n",
    ")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.title(\"Confusion Matrix - Neural Network (MLP)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Optional: function to predict direction for a new feature vector\n",
    "def predict_direction_nn(feature_vector, model=mlp, moves=MOVES):\n",
    "    \"\"\"\n",
    "    feature_vector: 1D numpy array of the same length as a row in X\n",
    "    Returns the predicted move label.\n",
    "    \"\"\"\n",
    "    feature_vector = feature_vector.reshape(1, -1)\n",
    "    pred_idx = model.predict(feature_vector)[0]\n",
    "    return moves[pred_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7rrb8XeG-qC"
   },
   "source": [
    "## Simple Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keJSgepeHCEv",
    "outputId": "ae9b2faf-856d-4652-d861-1b40477497b1"
   },
   "outputs": [],
   "source": [
    "# We only care about these directions\n",
    "BASIC_MOVES = [\"center\", \"left\", \"right\", \"up\", \"down\"]\n",
    "\n",
    "# Get their indices in the full MOVES list\n",
    "basic_move_indices = [MOVES.index(m) for m in BASIC_MOVES]\n",
    "\n",
    "# Keep only samples where the label is one of these 5\n",
    "train_mask = np.isin(y_train, basic_move_indices)\n",
    "test_mask = np.isin(y_test, basic_move_indices)\n",
    "\n",
    "X_train_basic = X_train[train_mask]\n",
    "y_train_basic = y_train[train_mask]\n",
    "X_test_basic = X_test[test_mask]\n",
    "y_test_basic = y_test[test_mask]\n",
    "\n",
    "print(\"5-direction training examples:\", X_train_basic.shape[0])\n",
    "print(\"5-direction test examples:\", X_test_basic.shape[0])\n",
    "\n",
    "label_map = {old_idx: new_idx for new_idx, old_idx in enumerate(basic_move_indices)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}  # if you want to go back later\n",
    "\n",
    "y_train_basic_remap = np.array([label_map[i] for i in y_train_basic])\n",
    "y_test_basic_remap = np.array([label_map[i] for i in y_test_basic])\n",
    "\n",
    "print(\"Unique remapped train labels:\", np.unique(y_train_basic_remap))\n",
    "print(\"Unique remapped test labels:\", np.unique(y_test_basic_remap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2Dm_F0ujHHSI",
    "outputId": "19803c8e-8ac0-4bbf-ffc6-f1daaea3cefb"
   },
   "outputs": [],
   "source": [
    "# Define a separate neural network for 5 basic directions\n",
    "mlp_basic_clr = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128),  # same architecture\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    batch_size=1,\n",
    "    learning_rate=\"adaptive\",\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "mlp_basic = make_pipeline(StandardScaler(), mlp_basic_clr)\n",
    "\n",
    "print(\"Training 5-direction MLP neural network...\")\n",
    "mlp_basic.fit(X_train_basic, y_train_basic_remap)\n",
    "\n",
    "# Predict on the filtered test set\n",
    "y_pred_basic = mlp_basic.predict(X_test_basic)\n",
    "\n",
    "# Evaluate performance\n",
    "nn_basic_accuracy = accuracy_score(y_test_basic_remap, y_pred_basic)\n",
    "print(\"\\n=== 5-Direction Neural Network (MLP) Performance ===\")\n",
    "print(f\"Test Accuracy (5 classes): {nn_basic_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n=== Classification Report (5 classes) ===\")\n",
    "print(classification_report(y_test_basic_remap, y_pred_basic, target_names=BASIC_MOVES))\n",
    "\n",
    "# Confusion matrix for the 5 directions\n",
    "cm_basic = confusion_matrix(y_test_basic_remap, y_pred_basic)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "disp_basic = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_basic, display_labels=BASIC_MOVES\n",
    ")\n",
    "disp_basic.plot(values_format=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - 5-Direction Neural Network (MLP)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxlHZBDtQgLe"
   },
   "source": [
    "## Only left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "15hp1hxqQket",
    "outputId": "40d383fc-ef8e-4411-aa1c-323a653892b1"
   },
   "outputs": [],
   "source": [
    "# We only care about these directions\n",
    "SUPER_BASIC_MOVES = [\"left\", \"right\"]\n",
    "\n",
    "# Get their indices in the full MOVES list\n",
    "basic_move_indices = [MOVES.index(m) for m in SUPER_BASIC_MOVES]\n",
    "\n",
    "# Keep only samples where the label is one of these 2\n",
    "train_mask = np.isin(y_train, basic_move_indices)\n",
    "test_mask = np.isin(y_test, basic_move_indices)\n",
    "\n",
    "X_train_lr = X_train[train_mask]\n",
    "y_train_lr = y_train[train_mask]\n",
    "X_test_lr = X_test[test_mask]\n",
    "y_test_lr = y_test[test_mask]\n",
    "\n",
    "print(\"2-direction training examples:\", X_train_lr.shape[0])\n",
    "print(\"2-direction test examples:\", X_test_lr.shape[0])\n",
    "\n",
    "label_map = {old_idx: new_idx for new_idx, old_idx in enumerate(basic_move_indices)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}  # if you want to go back later\n",
    "\n",
    "y_train_lr_remap = np.array([label_map[i] for i in y_train_lr])\n",
    "y_test_lr_remap = np.array([label_map[i] for i in y_test_lr])\n",
    "\n",
    "print(\"Unique remapped train labels:\", np.unique(y_train_lr_remap))\n",
    "print(\"Unique remapped test labels:\", np.unique(y_test_lr_remap))\n",
    "\n",
    "# Define a separate neural network for 5 basic directions\n",
    "mlp_only_left_right_clr = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128),  # same architecture\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    batch_size=1,\n",
    "    learning_rate=\"adaptive\",\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "mlp_only_left_right = make_pipeline(StandardScaler(), mlp_only_left_right_clr)\n",
    "\n",
    "print(\"Training 2-direction MLP neural network...\")\n",
    "mlp_only_left_right.fit(X_train_lr, y_train_lr_remap)\n",
    "\n",
    "# Predict on the filtered test set\n",
    "y_pred_lr = mlp_only_left_right.predict(X_test_lr)\n",
    "\n",
    "# Evaluate performance\n",
    "nn_lr_accuracy = accuracy_score(y_test_lr_remap, y_pred_lr)\n",
    "print(\"\\n=== 2-Direction Neural Network (MLP) Performance ===\")\n",
    "print(f\"Test Accuracy (2 classes): {nn_lr_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n=== Classification Report (2 classes) ===\")\n",
    "print(classification_report(y_test_lr_remap, y_pred_lr, target_names=SUPER_BASIC_MOVES))\n",
    "\n",
    "# Confusion matrix for the 2 directions\n",
    "cm_lr = confusion_matrix(y_test_lr_remap, y_pred_lr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "disp_lr = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_lr, display_labels=SUPER_BASIC_MOVES\n",
    ")\n",
    "disp_lr.plot(values_format=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - 2-Direction Neural Network (MLP)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xmf-2a7MoJK4",
    "outputId": "4a1e5c1f-da0f-4526-e1f8-3bbb78496309"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X_train: full 11-move training features\n",
    "# X_train_basic: only center/left/right/up/down\n",
    "# X_train_lr: only left/right samples\n",
    "\n",
    "# If you ALREADY have scalers, just assign them instead of fitting again:\n",
    "#   scaler_all = <your existing scaler for mlp>\n",
    "#   scaler_basic = <your existing scaler for mlp_basic>\n",
    "#   scaler_lr = <your existing scaler for mlp_only_left_right>\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "\n",
    "def save_mlp_with_scaler_to_onnx(model, onnx_path):\n",
    "    \"\"\"\n",
    "    Wraps (scaler â†’ model) in a Pipeline and saves as ONNX.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of input features\n",
    "    n_features = model.n_features_in_\n",
    "\n",
    "    initial_type = [(\"input\", FloatTensorType([None, n_features]))]\n",
    "\n",
    "    onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "    with open(onnx_path, \"wb\") as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "\n",
    "    print(f\"Saved ONNX model to {onnx_path}\")\n",
    "\n",
    "\n",
    "# 1) Full multi-move model\n",
    "save_mlp_with_scaler_to_onnx(model=mlp, onnx_path=\"./models/mlp_all_moves.onnx\")\n",
    "\n",
    "# 2) 5-direction model (center/left/right/up/down)\n",
    "save_mlp_with_scaler_to_onnx(\n",
    "    model=mlp_basic, onnx_path=\"./models/mlp_five_directions.onnx\"\n",
    ")\n",
    "\n",
    "# 3) Left/right-only model\n",
    "save_mlp_with_scaler_to_onnx(\n",
    "    model=mlp_only_left_right, onnx_path=\"./models/mlp_left_right.onnx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
